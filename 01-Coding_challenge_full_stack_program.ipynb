{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Puso9b4juIfk"
   },
   "source": [
    "This notebook was prepared by [Antoine Krajnc](https://github.com/antoinekrajnc). Source and license info is on [GitHub](https://github.com/donnemartin/interactive-coding-challenges)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IhkLFmE-uIfm"
   },
   "source": [
    "# Challenge Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JaqZas-NuIfn"
   },
   "source": [
    "Here is your first data science coding challenge. This is meant for people who would like to become a Junior Data Scientist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t66dvCWYuIfo"
   },
   "source": [
    "## Question 1 : How would you declare a ```name``` function in Python? \n",
    "### (0.25 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ZeqqbZuuIfq"
   },
   "source": [
    "A. ```def name():```\n",
    "\n",
    "B. ```function name():```\n",
    "\n",
    "C. ```name():```\n",
    "\n",
    "D. ```void name():```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WOidjxb7uIfr"
   },
   "outputs": [],
   "source": [
    "# Add the answer within the two quotes \n",
    "def answer1():\n",
    "    answer= \"\"\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bABWpQjBuIf0"
   },
   "source": [
    "## Question 2 : What is the data type of ```val = {'0':0, '1':1, '2': 2}``` ?\n",
    "### (0.25 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yO58syl5uIf1"
   },
   "source": [
    "A. ```list```\n",
    "\n",
    "B. ```dict```\n",
    "\n",
    "C. ```array```\n",
    "\n",
    "D. ```map```\n",
    "\n",
    "E. ```set```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zMM3cu2vuIf2"
   },
   "outputs": [],
   "source": [
    "def answer2():\n",
    "    answer = \"\"\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JFQq1cSauIf4"
   },
   "source": [
    "## Question 3 : Build a function ```average(table)```\n",
    "\n",
    "#### This function should return the mean of ```table``` given as parameter. ```table``` is a list and its items are always numbers\n",
    "\n",
    "#### ```average()``` should return 0 if ```table``` is empty.\n",
    "\n",
    "### (2.5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HklY8_xTuIf5"
   },
   "outputs": [],
   "source": [
    "def average(table):\n",
    "\n",
    "    return avg    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IvjA0pWcuIf7"
   },
   "source": [
    "## Question 4 : How would you create an instance ```point``` of the following object ? \n",
    "### (0.25 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zkAsWcIluIgB"
   },
   "source": [
    "```\n",
    "class Point():\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "       \n",
    "    def __init__(self, other):\n",
    "        return(self.x, self.y) == (other.x, other.y)\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rg7indn1uIgJ"
   },
   "source": [
    "A. ```point = new Point(10, 20)```\n",
    "\n",
    "B. ```point = Point(point(10, 20)```\n",
    "\n",
    "C. ```point = Point(10, 20)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J8NbYt1suIgK"
   },
   "outputs": [],
   "source": [
    "def answer4():\n",
    "    answer = \"\"\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z-JgZAneuIgP"
   },
   "source": [
    "## Question 5 : How do you write an ``AND`` operator in Python ? \n",
    "### (0.25 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HBDLi8TuuIgQ"
   },
   "source": [
    "A. ```&&```\n",
    "\n",
    "B. ```and```\n",
    "\n",
    "C. ```.```\n",
    "\n",
    "D. ```||```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CUC-ETQuuIgR"
   },
   "outputs": [],
   "source": [
    "def answer5():\n",
    "    answer = \"\"\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x-jYQn-kuIgY"
   },
   "source": [
    "## Question 6 : What is the difference between ```tuples``` &  ```lists```\n",
    "### (0.25 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KHlrJkckuIga"
   },
   "source": [
    "A. ```lists``` are ordered, ```tuples``` are not.\n",
    "\n",
    "B. ```lists``` can contain duplicates, ```tuples``` only have unique values.\n",
    "\n",
    "C. ```tuples``` can store different data types as items, ```lists``` cannot. \n",
    "\n",
    "D. ```tuples``` are immutable, ```lists``` are mutable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SvMh586OuIgh"
   },
   "outputs": [],
   "source": [
    "def answer6():\n",
    "    answer = \"\"\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y3yDz2_xuIgo"
   },
   "source": [
    "## Question 7 : The following code is located in  ```file.py```. When using command ```python3 file.py```, in which order each block of code will be executed?\n",
    "### (0.25 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4mqVsLjwuIgp"
   },
   "source": [
    "```\n",
    "#code block A\n",
    "\n",
    "def main():\n",
    "    #code block B\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n",
    "#code block C\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cMhYCSRxuIgp"
   },
   "source": [
    "A. ```A``` then ```B``` then ```C ```\n",
    "\n",
    "B. only ```B```\n",
    "\n",
    "C. ```A``` then ```B```\n",
    "\n",
    "D. ```A``` then ```C``` then ```B```\n",
    "\n",
    "E. ```A``` then ```C ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LvDIP6KWuIgq"
   },
   "outputs": [],
   "source": [
    "def answer7():\n",
    "    answer = \"\"\n",
    "    return answer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x2YybjPMuIgs"
   },
   "source": [
    "## Question 8 : Which of the following gives you the maximum value of ```values= [0, 1, 2]```? (Assume you can import any python librairy)\n",
    "### (0.5 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DkOjrJQWuIgt"
   },
   "source": [
    "A. ```max(values)```\n",
    "\n",
    "B. ```np.max(values)```\n",
    "\n",
    "C. ```pd.Series(values).max()```\n",
    "\n",
    "D. ```All of the above```\n",
    "\n",
    "E. ```None of the above```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "niEg-PZOuIgw"
   },
   "outputs": [],
   "source": [
    "def answer8():\n",
    "    answer = \"\"\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4TmKJ6ImuIg1"
   },
   "source": [
    "## Question 9 : You are building a function that returns all files that belongs to a given folder. What would be the best value to return if the given folder is empty?\n",
    "### (0.5 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iP2mtZicuIhJ"
   },
   "source": [
    "A. Function should return an empty list \n",
    "\n",
    "B. Function should return ```None```\n",
    "\n",
    "C. Function should raise an exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-M9BWzHIuIhK"
   },
   "outputs": [],
   "source": [
    "def answer9():\n",
    "    answer = \"\"\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LAHmb3cpuIhU"
   },
   "source": [
    "# Question 10: Count tiny pairs\n",
    "\n",
    "#### You are given two arrays of integers a and b of the same length, and an integer k. We will be iterating through array a from left to right, and simultaneously through array b from right to left, and looking at pairs $(x, y)$, where $x\\, \\epsilon\\, a$ and $y\\, \\epsilon\\, b$. Such a pair is called tiny if the concatenation $xy$ is strictly less than $k$.\n",
    "\n",
    "#### Your task is to return the number of tiny pairs that you'll encounter during the simultaneous iteration through a and b.\n",
    "\n",
    "### (4 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yxf5ZnrnuIhV"
   },
   "source": [
    "#### Example 1\n",
    "\n",
    "For ```a = [1, 2, 3]```, ```b = [1, 2, 3]```, and ```k = 31```, the output should be\n",
    "```countTinyPairs(a, b, k) = 2```.\n",
    "\n",
    "We're considering the following pairs during iteration:\n",
    "\n",
    "(1, 3). Their concatenation equals 13, which is less than 31, so the pair is tiny;\n",
    "\n",
    "(2, 2). Their concatenation equals 22, which is less than 31, so the pair is tiny;\n",
    "\n",
    "(3, 1). Their concatenation equals 31, which is not less than 31, so the pair is not tiny.\n",
    "\n",
    "As you can see, there are 2 tiny pairs during the iteration, so the answer is 2.\n",
    "\n",
    "#### Example 2\n",
    "\n",
    "For ```a = [16, 1, 4, 2, 14]```, ```b = [7, 11, 2, 0, 15]```, and ```k = 743```, the output should be\n",
    "```countTinyPairs(a, b, k) = 4```.\n",
    "\n",
    "We're considering the following pairs during iteration:\n",
    "\n",
    "(16, 15). Their concatenation equals 1615, which is greater than 743, so the pair is not tiny;\n",
    "\n",
    "(1, 0). Their concatenation equals 10, which is less than 743, so the pair is tiny;\n",
    "\n",
    "(4, 2). Their concatenation equals 42, which is less than 743, so the pair is tiny;\n",
    "\n",
    "(2, 11). Their concatenation equals 211, which is less than 743, so the pair is tiny;\n",
    "\n",
    "(14, 7). Their concatenation equals 147, which is less than 743, so the pair is tiny.\n",
    "There are 4 tiny pairs during the iteration, so the answer is 4.\n",
    "\n",
    "\n",
    "### Input/Output\n",
    "\n",
    "**execution time limit** 4 seconds (py3)\n",
    "\n",
    "**input** array.integer ```a```\n",
    "\n",
    "An array of non-negative integers.\n",
    "\n",
    "### Guaranteed constraints\n",
    "\n",
    "$0\\, \\leq$ ```a.length``` $\\leq\\, 105$\n",
    "\n",
    "$0\\, \\leq$ ```a[i]``` $\\leq\\, 104$\n",
    "\n",
    "**input** array.integer ```b```\n",
    "\n",
    "An array of non-negative integers.\n",
    "\n",
    "### Guaranteed constraints:\n",
    "\n",
    "```b.length``` = ```a.length```\n",
    "\n",
    "$0\\, \\leq$ ```b[i]``` $\\leq\\, 104$\n",
    "\n",
    "**input** integer ```k```\n",
    "\n",
    "An integer to compare concatenated pairs with.\n",
    "\n",
    "### Guaranteed constraints:\n",
    "$0\\, \\leq$ ```k``` $\\leq\\, 109$\n",
    "\n",
    "*output* integer\n",
    "\n",
    "The number of tiny pairs during the iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FTWlz0pduIhW"
   },
   "outputs": [],
   "source": [
    "def countTinyPairs(a, b, k):\n",
    "\n",
    "    return n_tinypairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mm-EsoFCuIhY"
   },
   "source": [
    "# Question 11 : Fred's Challenge\n",
    "\n",
    "Fred is a very predictable man. For instance, when he uses his laptop, all he does is watch TV shows. He keeps on watching TV shows until his battery dies. Also, he is a very meticulous man, i.e. he pays great attention to minute details. He has been keeping logs of every time he charged his laptop, which includes how long he charged his laptop for and after that how long was he able to watch the TV. Now, Fred wants to use this log to predict how long will he be able to watch TV for when he starts so that he can plan his activities after watching his TV shows accordingly.\n",
    "\n",
    "**Challenge**\n",
    "\n",
    "You are given access to Fred’s laptop charging log by reading from the file “trainingdata.txt”. The training data file will consist of 100 lines, each with 2 comma-separated numbers.\n",
    "\n",
    "The first number denotes the amount of time the laptop was charged.\n",
    "The second number denotes the amount of time the battery lasted.\n",
    "The training data file can be [downloaded here](https://s3.amazonaws.com/hr-testcases/399/assets/trainingdata.txt) (this will be the same training data used when your program is run). The input for each of the test cases will consist of exactly 1 number rounded to 2 decimal places. For each input, output 1 number: the amount of time you predict his battery will last.\n",
    "\n",
    "Sample Input\n",
    "\n",
    "1.50\n",
    "\n",
    "Sample Output\n",
    "\n",
    "3.00\n",
    "\n",
    "### (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(timecharged):\n",
    "    return batteryduration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3DFG6XF2uIhb"
   },
   "source": [
    "# Question 12 : Dices probabilities\n",
    "\n",
    "### (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1FR0HH3-uIhc"
   },
   "source": [
    "**Objective**\n",
    "\n",
    "In this challenge, we practice calculating probability.\n",
    "\n",
    "**Task**\n",
    "\n",
    "In a single toss of two fair (evenly-weighted) -sided dice, find the probability of that their sum will be at most 9.\n",
    "\n",
    "**Output Format**\n",
    "\n",
    "In the editor below, submit your answer as Plain Text in the form of an irreducible fraction , where  and  are both integers.\n",
    "\n",
    "Your answer should resemble something like:\n",
    "\n",
    "**3/4**  \n",
    "(This is NOT the answer, just a demonstration of the answer format.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6qXHL3oEuIhf"
   },
   "outputs": [],
   "source": [
    "def answer12():\n",
    "    answer = \"\"\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lqZRQWeeuIhq"
   },
   "source": [
    "## Question 13 : Which of the following is needed in K-means clustering? \n",
    "### (0.5 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_jioYMF3uIhs"
   },
   "source": [
    "A. Initial guess as to clusters centroïds\n",
    "\n",
    "B. Numbers of clusters\n",
    "\n",
    "C. Define distance metrics\n",
    "\n",
    "D. All the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DOU_VSaCuIh0"
   },
   "outputs": [],
   "source": [
    "def answer13():\n",
    "    answer = \"\"\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BV8Yf5BFuIh8"
   },
   "source": [
    "# Question 14 : What is the difference between supervised & unsupervised learning? \n",
    "### (0.5 pt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UEruLz53uIh9"
   },
   "source": [
    "A. Supervised learning doesn't need labelled data in the training set whereas unsupervised learning does\n",
    "\n",
    "B. Supervised learning needs labelled data in the training set whereas unsupervised learning does not\n",
    "\n",
    "C. Supervised learning is used in Machine Learning whereas unsupervised learning is used in Deep Learning\n",
    "\n",
    "D. None of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mD9Gu8wbuIh9"
   },
   "outputs": [],
   "source": [
    "def answer14():\n",
    "    answer = \"\"\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i6AfGnhPuIia"
   },
   "source": [
    "# Question 15 : What is bias / variance trade off ? \n",
    "\n",
    "### (0.5 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sXtzaJ89uIip"
   },
   "source": [
    "A. If you increase a ML model bias, it will systematically decrease variance and vice-versa\n",
    "\n",
    "B. Our goal as data scientist is to have the lowest bias & variance when building a model \n",
    "\n",
    "C. Bias corresponds to under-fitting and variance corresponds to over-fitting\n",
    "\n",
    "D. All of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dAqcHsFauIir"
   },
   "outputs": [],
   "source": [
    "def answer15():\n",
    "    answer = \"\"\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gBfzsNn9uIiw"
   },
   "source": [
    "# Question 16 : What is a confusion matrix useful for ? \n",
    "\n",
    "### (0.5 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B1yR1AdjuIix"
   },
   "source": [
    "A. To see bias in any Machine Learning model\n",
    "\n",
    "B. To assess performance of a classification model \n",
    "\n",
    "C. To see correlations between features \n",
    "\n",
    "D. To see colinearity between features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PA_aogqFuIix"
   },
   "outputs": [],
   "source": [
    "def answer16():\n",
    "    answer = \"\"\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mSKf9XBwuIi6"
   },
   "source": [
    "# Question 17 : What is recall ? \n",
    "\n",
    "**TP = True Positives**\n",
    "\n",
    "**P = Positives**\n",
    "\n",
    "**TN = True Negatives**\n",
    "\n",
    "**N = Negatives**\n",
    "\n",
    "**FP = False Positives**\n",
    "\n",
    "**FN = False Negatives**\n",
    "\n",
    "### (0.5 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uu3ZZjxQuIjS"
   },
   "source": [
    "A. ```TP / P```\n",
    "\n",
    "B. ```(TP + TN) / (P + N)```\n",
    "\n",
    "C. ```TP / (TP + FN)```\n",
    "\n",
    "D. ```TP / (TP + FP)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FQlQkkwiuIjT"
   },
   "outputs": [],
   "source": [
    "def answer17():\n",
    "    answer = \"\"\n",
    "    return answer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWMkQfStuIjc"
   },
   "source": [
    "# Question 18 : I can use cross-validation on a time series to improve the accuracy  \n",
    "### (0.5 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EiheElZTuIjv"
   },
   "source": [
    "A. True\n",
    "\n",
    "B. False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8pWufhKRuIjw"
   },
   "outputs": [],
   "source": [
    "def answer18():\n",
    "    answer = \"\"\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0WkHYglKuIj1"
   },
   "source": [
    "# Question 19 : What could you do to deal with overfitting ?\n",
    "\n",
    "### (0.5 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y9bigBx7uIj7"
   },
   "source": [
    "A. Use regularization technics like L1 or L2\n",
    "\n",
    "B. Use cross-validation technics like K-fold\n",
    "\n",
    "C. Use Principal Component Analysis \n",
    "\n",
    "D. Add trees in my random forest algorithm\n",
    "\n",
    "E. Remove rows in my dataset \n",
    "\n",
    "F. All of the above \n",
    "\n",
    "G. Answer A, answer B & answer C\n",
    "\n",
    "H. Answer A, answer B & answer D\n",
    "\n",
    "I. Answer A, answer C & answer D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HpWRWHLauIj7"
   },
   "outputs": [],
   "source": [
    "def answer19():\n",
    "    answer = \"\"\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "us2z3EMouIkF"
   },
   "source": [
    "# Question 20 : What is the difference between bagging & boosting ?\n",
    "\n",
    "### (0.5 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bUbq3cwjuIkF"
   },
   "source": [
    "A. Bagging & Boosting are both part of the Ensemble Learning. There are no difference \n",
    "\n",
    "B. Bagging sequentially improves weak learners whereas Boosting gets estimations from all learners at once\n",
    "\n",
    "C. Bagging gets estimations from all learners at once whereas Boosting sequentially improves weak learners\n",
    "\n",
    "D. Bagging is used only for decision trees whereas Boosting can be used of any models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a99gPEAuuIkG"
   },
   "outputs": [],
   "source": [
    "def answer20():\n",
    "    answer = \"\"\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ozYdaTZuIkP"
   },
   "source": [
    "# Unit Test\n",
    "\n",
    "**The following unit test is expected to fail until you solve the challenge.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nose\n",
      "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
      "Installing collected packages: nose\n",
      "Successfully installed nose-1.3.7\n"
     ]
    }
   ],
   "source": [
    "!pip install nose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error : <bound method TestFoo.test_response1 of <__main__.TestFoo object at 0x0000016973AA2F70>>\n",
      "error : <bound method TestFoo.test_response2 of <__main__.TestFoo object at 0x0000016973AA2F70>>\n",
      "error : <bound method TestFoo.test_response3 of <__main__.TestFoo object at 0x0000016973AA2F70>>\n",
      "error : <bound method TestFoo.test_response4 of <__main__.TestFoo object at 0x0000016973AA2F70>>\n",
      "error : <bound method TestFoo.test_response5 of <__main__.TestFoo object at 0x0000016973AA2F70>>\n",
      "error : <bound method TestFoo.test_response6 of <__main__.TestFoo object at 0x0000016973AA2F70>>\n",
      "error : <bound method TestFoo.test_response7 of <__main__.TestFoo object at 0x0000016973AA2F70>>\n",
      "error : <bound method TestFoo.test_response8 of <__main__.TestFoo object at 0x0000016973AA2F70>>\n",
      "error : <bound method TestFoo.test_response9 of <__main__.TestFoo object at 0x0000016973AA2F70>>\n",
      "error : <bound method TestFoo.test_response10 of <__main__.TestFoo object at 0x0000016973AA2F70>>\n",
      "error : <bound method TestFoo.test_response11 of <__main__.TestFoo object at 0x0000016973AA2F70>>\n",
      "error : <bound method TestFoo.test_response12 of <__main__.TestFoo object at 0x0000016973AA2F70>>\n",
      "error : <bound method TestFoo.test_response13 of <__main__.TestFoo object at 0x0000016973AA2F70>>\n",
      "error : <bound method TestFoo.test_response14 of <__main__.TestFoo object at 0x0000016973AA2F70>>\n",
      "error : <bound method TestFoo.test_response15 of <__main__.TestFoo object at 0x0000016973AA2F70>>\n",
      "error : <bound method TestFoo.test_response16 of <__main__.TestFoo object at 0x0000016973AA2F70>>\n",
      "error : <bound method TestFoo.test_response17 of <__main__.TestFoo object at 0x0000016973AA2F70>>\n",
      "error : <bound method TestFoo.test_response18 of <__main__.TestFoo object at 0x0000016973AA2F70>>\n",
      "error : <bound method TestFoo.test_response19 of <__main__.TestFoo object at 0x0000016973AA2F70>>\n",
      "error : <bound method TestFoo.test_response20 of <__main__.TestFoo object at 0x0000016973AA2F70>>\n",
      "thanks for taking the test, here is your score : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\AppData\\Local\\Temp\\ipykernel_27220\\437318032.py:3: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as pdt\n"
     ]
    }
   ],
   "source": [
    "# %load src/coding_challenge_full_stack_program_solutions.py\n",
    "from nose.tools import assert_equal\n",
    "import pandas.util.testing as pdt\n",
    "\n",
    "\n",
    "class TestFoo(object):\n",
    "\n",
    "    def __init__(self, score = 0):\n",
    "        self.score = score\n",
    "\n",
    "    def test_response1(self):\n",
    "        assert_equal(answer1(), \"A\")\n",
    "        self.score += 0.25\n",
    "\n",
    "    def test_response2(self):\n",
    "        assert_equal(answer2(), \"B\")\n",
    "        self.score += 0.25\n",
    "\n",
    "    def test_response3(self):\n",
    "        try:\n",
    "            assert average([3,1,3,4]) == 2.75\n",
    "            self.score += 2.5\n",
    "        except:\n",
    "            assert (average([3,1,3,4]) == 2.75).all()\n",
    "            self.score += 2.5\n",
    "\n",
    "    def test_response4(self):\n",
    "        assert_equal(answer4(), \"C\")\n",
    "        self.score += 0.25\n",
    "\n",
    "    def test_response5(self):\n",
    "        assert_equal(answer5(), \"B\")\n",
    "        self.score += 0.25\n",
    "\n",
    "    def test_response6(self):\n",
    "        assert_equal(answer6(), \"D\")\n",
    "        self.score += 0.25\n",
    "\n",
    "    def test_response7(self):\n",
    "        assert_equal(answer7(), \"A\")\n",
    "        self.score += 0.25\n",
    "\n",
    "    def test_response8(self):\n",
    "        assert_equal(answer8(), \"D\")\n",
    "        self.score += 0.5\n",
    "\n",
    "    def test_response9(self):\n",
    "        assert_equal(answer9(), \"A\")\n",
    "        self.score += 0.5\n",
    "\n",
    "    def test_response10(self):\n",
    "        assert countTinyPairs([16, 1, 4, 2, 14], [7, 11, 2, 0, 15], 743), 4\n",
    "        self.score += 4\n",
    "\n",
    "    def test_response11(self):\n",
    "        assert_equal(prediction(4.7), 8)\n",
    "        self.score += 5\n",
    "\n",
    "    def test_response12(self):\n",
    "        assert_equal(answer12(), \"5/6\")\n",
    "        self.score += 2\n",
    "\n",
    "    def test_response13(self):\n",
    "        assert_equal(answer13(), \"D\")\n",
    "        self.score += 0.5\n",
    "\n",
    "    def test_response14(self):\n",
    "        assert_equal(answer14(), \"B\")\n",
    "        self.score += 0.5\n",
    "\n",
    "    def test_response15(self):\n",
    "        assert_equal(answer15(), \"D\")\n",
    "        self.score += 0.5\n",
    "\n",
    "    def test_response16(self):\n",
    "        assert_equal(answer16(), \"B\")\n",
    "        self.score += 0.5\n",
    "\n",
    "    def test_response17(self):\n",
    "        assert_equal(answer17(), \"C\")\n",
    "        self.score += 0.5\n",
    "\n",
    "    def test_response18(self):\n",
    "        assert_equal(answer18(), \"B\")\n",
    "        self.score += 0.5\n",
    "\n",
    "    def test_response19(self):\n",
    "        assert_equal(answer19(), \"G\")\n",
    "        self.score += 0.5\n",
    "\n",
    "    def test_response20(self):\n",
    "        assert_equal(answer20(), \"C\")\n",
    "        self.score += 0.5\n",
    "\n",
    "    def print_scores(self):\n",
    "        print(\"thanks for taking the test, here is your score : {}\".format(self.score))\n",
    "\n",
    "def main():\n",
    "    test = TestFoo()\n",
    "\n",
    "    for func in [test.test_response1,\n",
    "                 test.test_response2,\n",
    "                 test.test_response3,\n",
    "                 test.test_response4,\n",
    "                 test.test_response5,\n",
    "                 test.test_response6,\n",
    "                 test.test_response7,\n",
    "                 test.test_response8,\n",
    "                 test.test_response9,\n",
    "                 test.test_response10,\n",
    "                 test.test_response11,\n",
    "                 test.test_response12,\n",
    "                 test.test_response13,\n",
    "                 test.test_response14,\n",
    "                 test.test_response15,\n",
    "                 test.test_response16,\n",
    "                 test.test_response17,\n",
    "                 test.test_response18,\n",
    "                 test.test_response19,\n",
    "                 test.test_response20\n",
    "                ]:\n",
    "        try:\n",
    "            func()\n",
    "        except:\n",
    "            print(\"error : {}\".format(func))\n",
    "\n",
    "    test.print_scores()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "1. Coding Challenge - FULL STACK PROGRAM.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "fbc4d3870518eee81184ced0d2279c769a0eca59aab465c4e7ec13e5e6c47a3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
